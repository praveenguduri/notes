
Individual Contributor or a leader role (leading a very small team of specialists) with deep technical expertise in following areas:

    - Data Platforms(Spark, Snowflake, Hive, Streaming, Databricks)
    - Public Cloud Services(AWS/GCP)
    - Microservice patterns, API design
    - Intermediate to Advanced Python or Java

* Guide data partners throughout the firm to onboard the analytical data into the enterprise data systems for analytical and machine learning.
* Own the responsibility of making the product successful in a fast-paced environment with deep focus on quality, scalability and architecture
* Provide tactical advice in solving technical issues as well as strategic guidance for the long-term reliability of the systems.
* Play SME role for application development teams to help Cloud, Big Data, Data Lake and Machine Learning application modernization.
* Play an instrumental role in building our state-of-the-art time series data platform that abstract away details and automate as much as possible, so it is easy to set up and operate continuously with very little intervention
* Develop utilities and tools to help the cloud data journey in the process.
* Research specific tools and Support assessment of new product/services across cloud data technology paradigm
* Motivate, engage, coach and provide leadership to a team while building an environment that is conducive to their development and delivery to the best of their ability


** Notes

A Configurable data pipeline is a data pipeline with intelligence built in to abstract away details and automate as much as possible, so it is easy to set up and operate continuously with very little intervention. As a result, data pipelines are fast to build and deploy, fault tolerant, adaptive, and self healing. Data engineering Framework is dedicated to building the intelligent data pipelines needed to power DataOps across hybrid and multi-cloud architectures
